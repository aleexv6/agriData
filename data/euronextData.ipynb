{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from seleniumbase import Driver\n",
    "from io import StringIO\n",
    "import time\n",
    "from datetime import datetime\n",
    "from unidecode import unidecode\n",
    "import database as db\n",
    "import pymongo\n",
    "from discord_webhook import DiscordWebhook\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'EBM': 'https://live.euronext.com/fr/product/commodities-futures/EBM-DPAR/settlement-prices',\n",
    "    'EMA': 'https://live.euronext.com/fr/product/commodities-futures/EMA-DPAR/settlement-prices',\n",
    "    'ECO': 'https://live.euronext.com/fr/product/commodities-futures/ECO-DPAR/settlement-prices'\n",
    "}\n",
    "\n",
    "months = {\n",
    "    'FEV': 'FEB',\n",
    "    'MAI': 'MAY',\n",
    "    'JUIN': 'JUN',\n",
    "    'AOU': 'AUG'\n",
    "}\n",
    "RESPONSE = '**####### EURONEXT FUTURES DATA #######\\n**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_db(df, RESPONSE=RESPONSE):\n",
    "    dbname = db.get_database()\n",
    "    collection_name_france = dbname[\"futures\"]\n",
    "    data = df.to_dict('records')\n",
    "    last_doc_france = collection_name_france.find_one(\n",
    "            sort=[( 'Date', pymongo.DESCENDING )]\n",
    "        )\n",
    "    if last_doc_france is not None:\n",
    "            if not df.empty:\n",
    "                if df['Date'].iloc[0] != last_doc_france['Date']:\n",
    "                    inserted = str(collection_name_france.insert_many(data))\n",
    "                    RESPONSE += inserted\n",
    "                else:\n",
    "                    RESPONSE += 'Euronext Futures : Document non inséré, doublon date avec le dernier document en base.'\n",
    "            else:\n",
    "                RESPONSE += 'NO DATA TO IMPORT TODAY, EMPTY DATAFRAME'\n",
    "    return RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maturity_to_expiration(series, months_map=months):\n",
    "    strs = series.apply(unidecode).str.upper()\n",
    "    month = strs.str.strip().str.split().str[0]\n",
    "    year = strs.str.strip().str.split().str[1].str[-2:]\n",
    "    mapped = month.map(months_map).fillna(month)\n",
    "    expi = mapped+year\n",
    "    return expi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapper(url):\n",
    "    driver = Driver(uc=True, incognito=True, headless=True) #set driver\n",
    "    driver.get(url)\n",
    "    driver.wait_for_element(\".table\")\n",
    "    html = driver.page_source #get html code from page\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    table = soup.find('table', class_='table') #find the datatable\n",
    "    tmp = pd.read_html(StringIO(str(table)))[0].iloc[:-1] #prep dataframe form table\n",
    "    driver.quit()\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_scrapped(urls, RESPONSE=RESPONSE):\n",
    "    df_lists = []\n",
    "    for idx, item in urls.items(): #loop throught tickers and URLs\n",
    "        retry = 0\n",
    "        while retry < 5:  # Retry up to 5 times\n",
    "            tmp = scrapper(item) #set scrapped df in tmp\n",
    "            if not tmp.empty: # if tmp not empty meaning we scrapped something\n",
    "                if len(tmp['Compens.'].unique()) == 1 or 'nan' in tmp['Compens.'].astype(str).values: #if only one unique compensation, it means it is either full nan values or not the full values -> we retry, or if their is at least one nan value in compens. -> we retry \n",
    "                    #retry\n",
    "                    print(f\"{idx} full data not received, retrying...\")\n",
    "                    time.sleep(300) #5m sleep\n",
    "                    retry += 1\n",
    "                    continue  # Retry the current iteration\n",
    "                else:\n",
    "                    #we good,\n",
    "                    tmp['Ticker'] = idx #add ticker to df\n",
    "                    tmp['Date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "                    df_lists.append(tmp)\n",
    "                    break\n",
    "            else: #if there is nothing scrapped\n",
    "                RESPONSE += f\"Error scrapping data, get empty dataframe for {idx}\"\n",
    "                break\n",
    "        else:\n",
    "            # Exceeded max retries, skip this item\n",
    "            RESPONSE += f'Skipping {idx} after max retries, no full data found\\n'\n",
    "       \n",
    "    df = pd.concat(df_lists) #concat into one df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_scrapped(urls).reset_index(drop=True)\n",
    "df['Expiration'] = maturity_to_expiration(df['Maturité'])\n",
    "df = df.rename(columns={'Ouvert': 'Open', 'Haut': 'High', 'Bas': 'Low', 'Compens.': 'Close', 'Position ouverte': 'Open Interest'})\n",
    "df = df[['Date', 'Ticker', 'Expiration', 'Open', 'High', 'Low', 'Close', 'Volume', 'Open Interest']]\n",
    "df['Close'] = df['Close'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = insert_db(df) #insert to db\n",
    "#Logs into my Discord server to be keep track of bugs \n",
    "webhook = DiscordWebhook(url=config.discordLogWebhookUrl, content=r)\n",
    "response = webhook.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
